{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "id": "y_Dn9rzyiqxi"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GGLKx-6qiz-_"
   },
   "source": [
    "Upload the labels.csv and processed_counts.csv files to colab or your local workspace.\n",
    "\n",
    "This data associates a cell barcode, such as \"AAAGCCTGGCTAAC-1\", to a certain cell type label, such as \"CD14+ Monocyte\". For each cell barcode, there are also log RNA seq counts of 765 different genes, such as HES4.\n",
    "\n",
    "label.csv stores the association between a cell barcode and a cell type label.\n",
    "\n",
    "processed_counts.csv stores the normalized log read counts for each cell, where each row represents a single cell, and each column represents a gene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "id": "WelsjSzviy4m"
   },
   "outputs": [],
   "source": [
    "labels_pd = pd.read_csv(\"labels.csv\")\n",
    "counts_pd = pd.read_csv(\"processed_counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "id": "aIX8kcTXi7EV"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>bulk_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAGCCTGGCTAAC-1</td>\n",
       "      <td>CD14+ Monocyte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAATTCGATGCACA-1</td>\n",
       "      <td>Dendritic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AACACGTGGTCTTT-1</td>\n",
       "      <td>CD56+ NK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAGTGCACGTGCTA-1</td>\n",
       "      <td>CD4+/CD25 T Reg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACACGAACGGAGTG-1</td>\n",
       "      <td>Dendritic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              index      bulk_labels\n",
       "0  AAAGCCTGGCTAAC-1   CD14+ Monocyte\n",
       "1  AAATTCGATGCACA-1        Dendritic\n",
       "2  AACACGTGGTCTTT-1         CD56+ NK\n",
       "3  AAGTGCACGTGCTA-1  CD4+/CD25 T Reg\n",
       "4  ACACGAACGGAGTG-1        Dendritic"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 2)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>HES4</th>\n",
       "      <th>TNFRSF4</th>\n",
       "      <th>SSU72</th>\n",
       "      <th>PARK7</th>\n",
       "      <th>RBP7</th>\n",
       "      <th>SRM</th>\n",
       "      <th>MAD2L2</th>\n",
       "      <th>AGTRAP</th>\n",
       "      <th>TNFRSF1B</th>\n",
       "      <th>...</th>\n",
       "      <th>ATP5O</th>\n",
       "      <th>MRPS6</th>\n",
       "      <th>TTC3</th>\n",
       "      <th>U2AF1</th>\n",
       "      <th>CSTB</th>\n",
       "      <th>SUMO3</th>\n",
       "      <th>ITGB2</th>\n",
       "      <th>S100B</th>\n",
       "      <th>PRMT2</th>\n",
       "      <th>MT-ND3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAGCCTGGCTAAC-1</td>\n",
       "      <td>-0.326</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>-0.728</td>\n",
       "      <td>-0.301</td>\n",
       "      <td>3.386</td>\n",
       "      <td>-0.531</td>\n",
       "      <td>2.016</td>\n",
       "      <td>3.377</td>\n",
       "      <td>4.841</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>-0.532</td>\n",
       "      <td>-0.341</td>\n",
       "      <td>0.303</td>\n",
       "      <td>1.404</td>\n",
       "      <td>4.294</td>\n",
       "      <td>0.519</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.636</td>\n",
       "      <td>4.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAATTCGATGCACA-1</td>\n",
       "      <td>1.171</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>0.795</td>\n",
       "      <td>-1.200</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.531</td>\n",
       "      <td>1.889</td>\n",
       "      <td>-0.486</td>\n",
       "      <td>-0.459</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.136</td>\n",
       "      <td>-0.532</td>\n",
       "      <td>-0.341</td>\n",
       "      <td>-0.905</td>\n",
       "      <td>2.849</td>\n",
       "      <td>-0.585</td>\n",
       "      <td>1.172</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>2.630</td>\n",
       "      <td>-0.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AACACGTGGTCTTT-1</td>\n",
       "      <td>-0.326</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>0.483</td>\n",
       "      <td>-1.200</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.531</td>\n",
       "      <td>-0.451</td>\n",
       "      <td>0.971</td>\n",
       "      <td>-0.459</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.136</td>\n",
       "      <td>2.606</td>\n",
       "      <td>-0.341</td>\n",
       "      <td>-0.905</td>\n",
       "      <td>-0.455</td>\n",
       "      <td>-0.585</td>\n",
       "      <td>0.722</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.663</td>\n",
       "      <td>-0.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAGTGCACGTGCTA-1</td>\n",
       "      <td>-0.326</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>1.134</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.531</td>\n",
       "      <td>-0.451</td>\n",
       "      <td>-0.486</td>\n",
       "      <td>-0.459</td>\n",
       "      <td>...</td>\n",
       "      <td>1.161</td>\n",
       "      <td>-0.532</td>\n",
       "      <td>-0.341</td>\n",
       "      <td>-0.905</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>-0.585</td>\n",
       "      <td>0.766</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.636</td>\n",
       "      <td>-0.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACACGAACGGAGTG-1</td>\n",
       "      <td>-0.326</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>-0.728</td>\n",
       "      <td>-0.607</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.531</td>\n",
       "      <td>-0.451</td>\n",
       "      <td>0.787</td>\n",
       "      <td>-0.459</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.136</td>\n",
       "      <td>0.839</td>\n",
       "      <td>1.679</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.534</td>\n",
       "      <td>-0.585</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.636</td>\n",
       "      <td>-0.490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 766 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0   HES4  TNFRSF4  SSU72  PARK7   RBP7    SRM  MAD2L2   \n",
       "0  AAAGCCTGGCTAAC-1 -0.326   -0.191 -0.728 -0.301  3.386 -0.531   2.016  \\\n",
       "1  AAATTCGATGCACA-1  1.171   -0.191  0.795 -1.200 -0.174 -0.531   1.889   \n",
       "2  AACACGTGGTCTTT-1 -0.326   -0.191  0.483 -1.200 -0.174 -0.531  -0.451   \n",
       "3  AAGTGCACGTGCTA-1 -0.326   -0.191  1.134 -0.157 -0.174 -0.531  -0.451   \n",
       "4  ACACGAACGGAGTG-1 -0.326   -0.191 -0.728 -0.607 -0.174 -0.531  -0.451   \n",
       "\n",
       "   AGTRAP  TNFRSF1B  ...  ATP5O  MRPS6   TTC3  U2AF1   CSTB  SUMO3  ITGB2   \n",
       "0   3.377     4.841  ... -0.146 -0.532 -0.341  0.303  1.404  4.294  0.519  \\\n",
       "1  -0.486    -0.459  ... -1.136 -0.532 -0.341 -0.905  2.849 -0.585  1.172   \n",
       "2   0.971    -0.459  ... -1.136  2.606 -0.341 -0.905 -0.455 -0.585  0.722   \n",
       "3  -0.486    -0.459  ...  1.161 -0.532 -0.341 -0.905 -0.119 -0.585  0.766   \n",
       "4   0.787    -0.459  ... -1.136  0.839  1.679 -0.108 -0.534 -0.585 -0.007   \n",
       "\n",
       "   S100B  PRMT2  MT-ND3  \n",
       "0  -0.21 -0.636   4.011  \n",
       "1  -0.21  2.630  -0.490  \n",
       "2  -0.21  0.663  -0.490  \n",
       "3  -0.21 -0.636  -0.490  \n",
       "4  -0.21 -0.636  -0.490  \n",
       "\n",
       "[5 rows x 766 columns]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 766)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_pd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUxSCyz7jBQf"
   },
   "source": [
    "Shuffle your data. Make sure your labels and the counts are shuffled together.\n",
    "\n",
    "Split into train and test sets (80:20 split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "id": "XDTqBhcA7V8t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                index                   bulk_labels\n",
      "232  GGGCAAGAAGGCGA-3  CD8+/CD45RA+ Naive Cytotoxic\n",
      "349  TTTCAGTGTCACGA-4                CD14+ Monocyte\n",
      "74   TAACATGACTTGAG-1                     Dendritic\n",
      "29   CATCCCGATCTGGA-1                     Dendritic\n",
      "426  TCGGCACTGTTGAC-5                     Dendritic\n",
      "..                ...                           ...\n",
      "282  AGACCTGAGACGTT-4                     Dendritic\n",
      "445  AGACCTGATACTTC-6                CD14+ Monocyte\n",
      "454  ATTGAAACAGATCC-6                CD14+ Monocyte\n",
      "510  TGGTTACTTGCATG-6                      CD56+ NK\n",
      "413  GGCTAAACTCTTTG-5           CD4+/CD45RO+ Memory\n",
      "\n",
      "[700 rows x 2 columns]\n",
      "           Unnamed: 0   HES4  TNFRSF4  SSU72  PARK7   RBP7    SRM  MAD2L2   \n",
      "232  GGGCAAGAAGGCGA-3 -0.326   -0.191  0.599  0.286 -0.174 -0.531   1.588  \\\n",
      "349  TTTCAGTGTCACGA-4  1.013   -0.191 -0.728  0.325 -0.174 -0.531  -0.451   \n",
      "74   TAACATGACTTGAG-1 -0.326   -0.191  0.238 -0.659 -0.174  3.125  -0.451   \n",
      "29   CATCCCGATCTGGA-1  1.076   -0.191  0.698 -0.402 -0.174 -0.531  -0.451   \n",
      "426  TCGGCACTGTTGAC-5 -0.326   -0.191 -0.728 -0.374 -0.174 -0.531   0.683   \n",
      "..                ...    ...      ...    ...    ...    ...    ...     ...   \n",
      "282  AGACCTGAGACGTT-4 -0.326   -0.191 -0.728  0.274 -0.174 -0.531  -0.451   \n",
      "445  AGACCTGATACTTC-6 -0.326   -0.191 -0.728  0.014 -0.174 -0.531  -0.451   \n",
      "454  ATTGAAACAGATCC-6  1.199    3.203  0.824 -0.331 -0.174 -0.531  -0.451   \n",
      "510  TGGTTACTTGCATG-6 -0.326   -0.191  1.497  0.669 -0.174 -0.531  -0.451   \n",
      "413  GGCTAAACTCTTTG-5 -0.326   -0.191  1.002  1.221 -0.174  0.287  -0.451   \n",
      "\n",
      "     AGTRAP  TNFRSF1B  ...  ATP5O  MRPS6   TTC3  U2AF1   CSTB  SUMO3  ITGB2   \n",
      "232  -0.486    -0.459  ...  1.319  2.906  4.724 -0.905  0.289 -0.585 -0.387  \\\n",
      "349   1.153    -0.459  ... -0.296  1.232 -0.341  0.120  0.326 -0.585 -0.371   \n",
      "74   -0.486     0.605  ... -0.540 -0.532 -0.341 -0.905  2.409 -0.585 -0.561   \n",
      "29   -0.486    -0.459  ... -0.256 -0.532 -0.341  0.168  0.392 -0.585 -0.340   \n",
      "426   0.402    -0.459  ... -0.226  0.424 -0.341 -0.350 -0.699  1.658 -0.671   \n",
      "..      ...       ...  ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "282  -0.486     0.990  ...  2.112 -0.532  2.172  0.086 -0.401  0.749  1.508   \n",
      "445  -0.486     3.120  ... -0.467  0.872 -0.341 -0.089 -1.080 -0.585 -0.504   \n",
      "454  -0.486    -0.459  ... -0.179 -0.532 -0.341  0.263 -0.279 -0.585  1.960   \n",
      "510  -0.486    -0.459  ... -0.450 -0.532 -0.341  0.770 -1.080 -0.585  0.045   \n",
      "413  -0.486    -0.459  ... -0.602 -0.532  1.310  0.397 -0.634 -0.585 -1.026   \n",
      "\n",
      "     S100B  PRMT2  MT-ND3  \n",
      "232  -0.21 -0.636  -0.490  \n",
      "349  -0.21 -0.636  -0.490  \n",
      "74   -0.21  2.472  -0.490  \n",
      "29   -0.21 -0.636  -0.490  \n",
      "426  -0.21  0.155  -0.490  \n",
      "..     ...    ...     ...  \n",
      "282  -0.21 -0.636  -0.490  \n",
      "445  -0.21 -0.636   2.549  \n",
      "454  -0.21 -0.636   1.686  \n",
      "510  -0.21 -0.636   1.070  \n",
      "413  -0.21 -0.636  -0.490  \n",
      "\n",
      "[700 rows x 766 columns]\n"
     ]
    }
   ],
   "source": [
    "# create random array for shuffling\n",
    "index_a = np.arange(len(labels_pd))\n",
    "np.random.shuffle(index_a)\n",
    "\n",
    "# shuffle rows of both datasets based on array\n",
    "labels_pd = labels_pd.iloc[index_a]\n",
    "counts_pd = counts_pd.iloc[index_a]\n",
    "\n",
    "# print\n",
    "print(labels_pd)\n",
    "print(counts_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train, labels_test, counts_train, counts_test = train_test_split(labels_pd, counts_pd, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shapes:  (560, 2) (560, 766)\n",
      "Test set shapes:  (140, 2) (140, 766)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set shapes: \", labels_train.shape, counts_train.shape)\n",
    "print(\"Test set shapes: \", labels_test.shape, counts_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHIg7i1k7U-G"
   },
   "source": [
    "Create a fully connected neural network for your autoencoder. Your latent space can be of any size less than or equal to 64. Too large may result in a poor visualization, and too small may result in high loss. 32 is a good starting point.\n",
    "\n",
    "Consider using more than 1 hidden layer, and a sparcity constraint (l1 regularization).\n",
    "\n",
    "Have an encoder model which is a model of only the layers for the encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "id": "b8mvigLP7Sej"
   },
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size, latent_size):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, latent_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, input_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "id": "Gk1sfdNe76Kl"
   },
   "outputs": [],
   "source": [
    "# load training and testing datasets\n",
    "labels_train, labels_test, counts_train, counts_test = train_test_split(labels_pd, counts_pd, test_size=0.2, random_state=42)\n",
    "\n",
    "# only select columns with numerical data\n",
    "counts_train = counts_train.iloc[:, 1:].values\n",
    "counts_test = counts_test.iloc[:, 1:].values\n",
    "\n",
    "# convert data to Torch tensor\n",
    "counts_train = torch.tensor(counts_train, dtype=torch.float32)\n",
    "counts_test = torch.tensor(counts_test, dtype=torch.float32)\n",
    "\n",
    "# define autoencoder loss function\n",
    "input_size = counts_train.shape[1]\n",
    "latent_size = 32\n",
    "model = Autoencoder(input_size, latent_size)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# use L1 regularization for optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjQr4OYW76bN"
   },
   "source": [
    "Train your autoencoding using MSE loss.\n",
    "\n",
    "Finally, identify the parameters which don't overfit, and use the same model architecture and train on all of the data together.\n",
    "\n",
    "With a latent space size of 32, aim for 0.9 MSE loss on your test set, 0.95 with regularization. You will not be graded strictly on a loss cutoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u4Q6KU3c8u-E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 1.0000\n",
      "Epoch [2/100], Train Loss: 0.9914\n",
      "Epoch [3/100], Train Loss: 0.9787\n",
      "Epoch [4/100], Train Loss: 0.9708\n",
      "Epoch [5/100], Train Loss: 0.9612\n",
      "Epoch [6/100], Train Loss: 0.9543\n",
      "Epoch [7/100], Train Loss: 0.9500\n",
      "Epoch [8/100], Train Loss: 0.9463\n",
      "Epoch [9/100], Train Loss: 0.9424\n",
      "Epoch [10/100], Train Loss: 0.9384\n",
      "Epoch [11/100], Train Loss: 0.9368\n",
      "Epoch [12/100], Train Loss: 0.9358\n",
      "Epoch [13/100], Train Loss: 0.9353\n",
      "Epoch [14/100], Train Loss: 0.9351\n",
      "Epoch [15/100], Train Loss: 0.9329\n",
      "Epoch [16/100], Train Loss: 0.9314\n",
      "Epoch [17/100], Train Loss: 0.9299\n",
      "Epoch [18/100], Train Loss: 0.9294\n",
      "Epoch [19/100], Train Loss: 0.9303\n",
      "Epoch [20/100], Train Loss: 0.9287\n",
      "Epoch [21/100], Train Loss: 0.9272\n",
      "Epoch [22/100], Train Loss: 0.9260\n",
      "Epoch [23/100], Train Loss: 0.9255\n",
      "Epoch [24/100], Train Loss: 0.9238\n",
      "Epoch [25/100], Train Loss: 0.9227\n",
      "Epoch [26/100], Train Loss: 0.9210\n",
      "Epoch [27/100], Train Loss: 0.9207\n",
      "Epoch [28/100], Train Loss: 0.9213\n",
      "Epoch [29/100], Train Loss: 0.9217\n",
      "Epoch [30/100], Train Loss: 0.9200\n",
      "Epoch [31/100], Train Loss: 0.9194\n",
      "Epoch [32/100], Train Loss: 0.9180\n",
      "Epoch [33/100], Train Loss: 0.9167\n",
      "Epoch [34/100], Train Loss: 0.9184\n",
      "Epoch [35/100], Train Loss: 0.9183\n",
      "Epoch [36/100], Train Loss: 0.9197\n",
      "Epoch [37/100], Train Loss: 0.9169\n",
      "Epoch [38/100], Train Loss: 0.9148\n",
      "Epoch [39/100], Train Loss: 0.9138\n",
      "Epoch [40/100], Train Loss: 0.9128\n",
      "Epoch [41/100], Train Loss: 0.9131\n",
      "Epoch [42/100], Train Loss: 0.9150\n",
      "Epoch [43/100], Train Loss: 0.9170\n",
      "Epoch [44/100], Train Loss: 0.9138\n",
      "Epoch [45/100], Train Loss: 0.9083\n",
      "Epoch [46/100], Train Loss: 0.9055\n",
      "Epoch [47/100], Train Loss: 0.9046\n",
      "Epoch [48/100], Train Loss: 0.9048\n",
      "Epoch [49/100], Train Loss: 0.9058\n",
      "Epoch [50/100], Train Loss: 0.9071\n",
      "Epoch [51/100], Train Loss: 0.9117\n",
      "Epoch [52/100], Train Loss: 0.9109\n",
      "Epoch [53/100], Train Loss: 0.9066\n",
      "Epoch [54/100], Train Loss: 0.9039\n",
      "Epoch [55/100], Train Loss: 0.9010\n",
      "Epoch [56/100], Train Loss: 0.8995\n",
      "Epoch [57/100], Train Loss: 0.8981\n",
      "Epoch [58/100], Train Loss: 0.8979\n",
      "Epoch [59/100], Train Loss: 0.8980\n",
      "Epoch [60/100], Train Loss: 0.8955\n",
      "Epoch [61/100], Train Loss: 0.8963\n",
      "Epoch [62/100], Train Loss: 0.8963\n",
      "Epoch [63/100], Train Loss: 0.8980\n",
      "Epoch [64/100], Train Loss: 0.8989\n",
      "Epoch [65/100], Train Loss: 0.8978\n",
      "Epoch [66/100], Train Loss: 0.8939\n",
      "Epoch [67/100], Train Loss: 0.8909\n",
      "Epoch [68/100], Train Loss: 0.8905\n",
      "Epoch [69/100], Train Loss: 0.8881\n",
      "Epoch [70/100], Train Loss: 0.8881\n",
      "Epoch [71/100], Train Loss: 0.8857\n"
     ]
    }
   ],
   "source": [
    "# run autoencoder on train set\n",
    "n_epochs = 100\n",
    "batch_size = 32\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = 0\n",
    "    for i in range(0, counts_train.shape[0], batch_size):\n",
    "        inputs = counts_train[i:i+batch_size]\n",
    "        model.zero_grad()\n",
    "        encoded, decoded = model(inputs)\n",
    "        loss = criterion(decoded, inputs) + 1e-3 * torch.mean(torch.abs(encoded))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * inputs.shape[0]\n",
    "    train_loss /= counts_train.shape[0]\n",
    "    print('Epoch [{}/{}], Train Loss: {:.4f}'.format(epoch+1, n_epochs, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Trjfxkk8wyg"
   },
   "outputs": [],
   "source": [
    "# run autoencoder on test set\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for i in range(0, counts_test.shape[0], batch_size):\n",
    "        inputs = counts_test[i:i+batch_size]\n",
    "        encoded, decoded = model(inputs)\n",
    "        loss = criterion(decoded, inputs)\n",
    "        test_loss += loss.item() * inputs.shape[0]\n",
    "test_loss /= counts_test.shape[0]\n",
    "print('Test Loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yweQRGit8xDX"
   },
   "source": [
    "Use PCA and t-SNE on the dataset.\n",
    "\n",
    "Then use PCA on the latent space representation of the dataset.\n",
    "\n",
    "Plot all of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jGa5B6Ir9KN4"
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "counts_pd1 = pd.read_csv(\"processed_counts.csv\", index_col=0)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(counts_pd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I2xcMPP09KxV"
   },
   "outputs": [],
   "source": [
    "# t-SNE\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "X_tsne = tsne.fit_transform(X_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfOYsI9S9K5M"
   },
   "source": [
    "Compare the results of PCA, t-SNE, and your autoencoder as ways to visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1DPmGoHo9uwx",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the y variable for coloring the plot\n",
    "y = labels_pd.iloc[:, 1].values\n",
    "\n",
    "# plot the PCA results\n",
    "sns.scatterplot(\n",
    "    x=X_pca[:,0], y=X_pca[:,1],\n",
    "    hue=y,\n",
    "    palette=sns.color_palette(\"hls\", 10),\n",
    "    legend=False,\n",
    "    alpha=0.75\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1])\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.title('PCA Plot')\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract cell types from labels_train\n",
    "cell_types = labels_train.iloc[:, 1]\n",
    "\n",
    "# Get the encoded representation of the dataset\n",
    "with torch.no_grad():\n",
    "    encoded, _ = model(counts_train)\n",
    "    encoded = encoded.numpy()\n",
    "\n",
    "# Perform PCA on the encoded data\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(encoded)\n",
    "\n",
    "# Plot the PCA-reduced data with color-coded cell types\n",
    "fig, ax = plt.subplots()\n",
    "for ct in cell_types.unique():\n",
    "    ix = cell_types == ct\n",
    "    ax.scatter(X_pca[ix, 0], X_pca[ix, 1], label=ct)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the t-SNE results\n",
    "sns.scatterplot(\n",
    "    x=X_tsne[:,0], y=X_tsne[:,1],\n",
    "    hue=y,\n",
    "    palette=sns.color_palette('hls', 10),\n",
    "    legend=False,\n",
    "    alpha=0.75\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Final Project Part 1 - Autoencoder",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
